05. 성능 평가 지표

이번 장에서는 연속형 예측변수가 아닌, 범주형 예측변수를 가진 예측모델의 성능평가 지표에 대해 다루겠다. 

(1) 오차행렬

오차행렬 (Confusion Matrix)로 부터 TP(True Positive) , FP(False Positive), TN(True Negative), FN(False Negative)

1. 정확도 (Accuracy) = TP / ALL -> 전체 중 맞게 예측할 확률

2. 정밀도 (Precision) = TP / (TP+FP) -> 맞다고 예측한 것들 중 실제로 맞는 것일 확률 

3. 민감도 (Sensitivity) = TP/ (TP+FN) -> 실제로 맞았는데 맞다고 예측할 확률 

4. 특이도 (Specificity) = TN / (TN+FP) -> 실제로 틀렸는데 틀렸다고 예측할 확률 

5. F1-score =  (2*precision*recall) / (precision+recall) -> 정밀도와 민감도는 서로 trade-off 관계를 가진다. 두 지표가 어느 한쪽에 치우치지 않았을때 가장 큰 값을 가진다

** 예를 들어, 클래스 불균형이 큰 데이터의 경우 (스팸메일, 암 진단 데이터 등등) 정확도로 모델의 성능을 예측을 하는 것은 무의미하다. 

이럴 경우, 단순 정확도 보다는 민감도 지표를 쓰는 것이 더 정확하다


(2) ROC 곡선 

x축이 민감도, y축이 1-특이도 값을 가짐. 이진 분류 문제에서 레이블 분류 기준이 되는 확률의 임계값에 따른 fpr과 tpr의 비율에 따른 그래프. 

(0,0) 과 (1,1)을 잇는 기울기가 45도인 선 -> 50:50의 확률로 찍었을 때 맞출 확률. 이 선 보다 아래로 roc curve사 나오는 경우: random-guessing 보다 성능이 안 좋은 모델임

(0,1)지점에 근접한 양상을 보이는 ROC곡선의 모델이 성능이 좋은 모델이라고 볼수 있다. 

(3) AUC

ROC 곡선 아래의 면적이다. 0~1사이의 값을 가지게 되는데,  1에 가까울수록 성능이 좋은 모델이 된다.